{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, value=None, left=None, right=None):\n",
    "        self.feature = feature # feature index\n",
    "        self.threshold = threshold # feature threshold\n",
    "        self.value = value # feature index majority\n",
    "        self.left = left # child nodes\n",
    "        self.right = right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "from statistics import mode\n",
    "import numpy as np\n",
    "\n",
    "def pure(y):\n",
    "    if len(set(y)) == 1: # if all the same classes in remaining \n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def gini(y):\n",
    "    counts = list(Counter(y).values())\n",
    "    p = 0\n",
    "    for count in counts:\n",
    "        p += (count / len(y)) ** 2\n",
    "    return 1 - p\n",
    "\n",
    "def split(x, y, minleaf, nfeat):\n",
    "    features = random.sample(range(len(x[0])), nfeat) # random features selecting\n",
    "    \n",
    "    best_gini = 1\n",
    "    best_feature = None\n",
    "    best_threshold = None\n",
    "    best_left_indices = []\n",
    "    best_right_indices = []\n",
    "\n",
    "    for feature_index in range(len(features)):\n",
    "        values = [a[feature_index] for a in x]\n",
    "        for t in range(len(values)):\n",
    "            left_indices = []\n",
    "            right_indices = []\n",
    "            right_values = []\n",
    "            for i, a in enumerate(x): # indices lower than threshold\n",
    "                if a[feature_index] <= values[t]:\n",
    "                    left_indices.append(i)\n",
    "                else:\n",
    "                    right_indices.append(i)\n",
    "                    right_values.append(a[feature_index])\n",
    "\n",
    "            if len(left_indices) >= minleaf and len(right_indices) >= minleaf: # minleaf criteria\n",
    "                left_gini = gini([y[i] for i in left_indices])\n",
    "                right_gini = gini([y[i] for i in right_indices])\n",
    "\n",
    "                weighted_gini = (len(left_indices) / len(y)) * left_gini + (len(right_indices) / len(y)) * right_gini # weighted based on size\n",
    "\n",
    "                if weighted_gini < best_gini:\n",
    "                    best_gini = weighted_gini\n",
    "                    best_feature = feature_index\n",
    "                    right_values.sort()\n",
    "                    best_threshold = (values[t] + right_values[0]) / 2\n",
    "                    best_left_indices = left_indices\n",
    "                    best_right_indices = right_indices\n",
    "\n",
    "    # from indices to rows\n",
    "    best_left_x = [a for i, a in enumerate(x) if i in best_left_indices]\n",
    "    best_right_x = [a for i, a in enumerate(x) if i in best_right_indices]\n",
    "    best_left_y = [a for i, a in enumerate(y) if i in best_left_indices]\n",
    "    best_right_y = [a for i, a in enumerate(y) if i in best_right_indices]\n",
    "\n",
    "    return best_feature, best_threshold, best_left_x, best_right_x, best_left_y, best_right_y\n",
    "\n",
    "\n",
    "def tree_grow(x, y, nmin, minleaf, nfeat):\n",
    "    # nmin: if a node contains fewer cases than nmin, it becomes a leaf node.\n",
    "    # minleaf: a split that creates a node with fewer than minleaf observations is not acceptable.\n",
    "    #If there is no split that meets the minleaf constraint, the node becomes a leaf node. use GINI\n",
    "    #nfeat we first draw at random nfeat features from which the best split is to be selected.\n",
    "\n",
    "    if pure(y): # if pure return majority class\n",
    "        return Node(value=mode(y))\n",
    "\n",
    "    if len(y) < nmin: # if fewer cases than nmin majority class\n",
    "        return Node(value=mode(y))\n",
    "\n",
    "    feature, threshold, leftx, rightx, lefty, righty = split(x, y, minleaf, nfeat) # GINI search\n",
    "    print()\n",
    "    # print('feature split', feature)\n",
    "    # print('leftx', leftx)\n",
    "    # print('lefty', lefty)\n",
    "    # print('rightx', rightx)\n",
    "    # print('righty', righty)\n",
    "    # print()\n",
    "    if feature == None: # no split so node becomes leaf\n",
    "        return Node(value=mode(y))\n",
    "\n",
    "    left_child = tree_grow(leftx, lefty, nmin, minleaf, nfeat)\n",
    "    right_child = tree_grow(rightx, righty, nmin, minleaf, nfeat)\n",
    "\n",
    "    parent = Node()\n",
    "    parent.feature = feature\n",
    "    parent.threshold = threshold \n",
    "    parent.left = left_child\n",
    "    parent.right = right_child\n",
    "    return parent\n",
    "\n",
    "        \n",
    "def tree_pred(x, tr):\n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        current_node = tr\n",
    "        while current_node.value == None:\n",
    "            if x[i][current_node.feature] <= current_node.threshold:\n",
    "                current_node = current_node.left\n",
    "            else:\n",
    "                current_node = current_node.right\n",
    "        predictions.append(current_node.value)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "def tree_grow_b(x, y, nmin, minleaf, nfeat, m):\n",
    "    trees = []\n",
    "\n",
    "    for _ in range(m):\n",
    "        bootstrap_i = np.random.choice(len(x), len(x), replace=True)\n",
    "        x_b = [x[i] for i in bootstrap_i]\n",
    "        y_b = [y[i] for i in bootstrap_i]\n",
    "        trees.append(tree_grow(x_b, y_b, nmin, minleaf, nfeat))\n",
    "\n",
    "    return trees\n",
    "\n",
    "\n",
    "def tree_pred_b(trees, x):\n",
    "    outcomes = []\n",
    "    new_y = []\n",
    "    for tree in trees:\n",
    "        outcomes.append(tree_pred(x, tree))\n",
    "\n",
    "    for i in range(len(outcomes[0])):\n",
    "        new_y.append([a[i] for a in outcomes])\n",
    "        \n",
    "    new_y = [mode(a) for a in new_y]\n",
    "    return new_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[0, 0, 0, 0, 0, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'credit.txt'\n",
    "df = pd.read_csv(file_path, delimiter=',')\n",
    "x = df.drop(columns='class').values.tolist()\n",
    "y = df['class'].values.tolist()\n",
    "\n",
    "tree = tree_grow_b(x,y, 2, 1, 5, 4)\n",
    "print(tree_pred_b(tree, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "tree prediction on x:\n",
      "prediction [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
      "actual y [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
      "\n",
      "\n",
      "----- node 1 ------\n",
      "feature 3\n",
      "threshold 36.0\n",
      "----- node 1 - > 2 left -----\n",
      "feature 0\n",
      "threshold 37.0\n",
      "value None\n",
      "----- node 1 -> 2 right -----\n",
      "feature None\n",
      "threshold None\n",
      "value 1\n",
      "----- node 2 -> 3 left -----\n",
      "feature None\n",
      "threshold None\n",
      "value 0\n",
      "----- node 2 -> 3 right -----\n",
      "feature 1\n",
      "threshold 0.5\n",
      "value None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'credit.txt'\n",
    "df = pd.read_csv(file_path, delimiter=',')\n",
    "x = df.drop(columns='class').values.tolist()\n",
    "y = df['class'].values.tolist()\n",
    "\n",
    "tree = tree_grow(x,y, 2, 1, 5)\n",
    "\n",
    "print('tree prediction on x:')\n",
    "print('prediction', tree_pred(x,tree))\n",
    "print('actual y', y)\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('----- node 1 ------')\n",
    "print('feature', tree.feature)\n",
    "print('threshold', tree.threshold)\n",
    "print('----- node 1 - > 2 left -----')\n",
    "print('feature', tree.left.feature)\n",
    "print('threshold', tree.left.threshold)\n",
    "print('value', tree.left.value)\n",
    "print('----- node 1 -> 2 right -----')\n",
    "print('feature', tree.right.feature)\n",
    "print('threshold', tree.right.threshold)\n",
    "print('value', tree.right.value)\n",
    "print('----- node 2 -> 3 left -----')\n",
    "print('feature', tree.left.left.feature)\n",
    "print('threshold', tree.left.left.threshold)\n",
    "print('value', tree.left.left.value)\n",
    "print('----- node 2 -> 3 right -----')\n",
    "print('feature', tree.left.right.feature)\n",
    "print('threshold', tree.left.right.threshold)\n",
    "print('value', tree.left.right.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boom net niet zelfde als in slides, daar eerste split op feature 3 maar op 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "df = pd.read_csv('pima.txt', header=None)\n",
    "x = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "tree = tree_grow(x,y, 20, 5, 8)\n",
    "\n",
    "cm = confusion_matrix(y, tree_pred(x, tree))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 2.0 Ecplise data as training set \n",
    "train_data = pd.read_csv('eclipse-metrics-packages-2.0.csv', delimiter=';')\n",
    "\n",
    "# Load 3.0 Ecplise data as test set\n",
    "test_data = pd.read_csv('eclipse-metrics-packages-3.0.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All 41 predictor variables \n",
    "pred_variables = ['FOUT_avg', 'FOUT_max', 'FOUT_sum',\n",
    "                  'MLOC_avg', 'MLOC_max', 'MLOC_sum',\n",
    "                  'NBD_avg', 'NBD_max', 'NBD_sum',\n",
    "                  'PAR_avg', 'PAR_max', 'PAR_sum',\n",
    "                  'VG_avg', 'VG_max', 'VG_sum',\n",
    "                  'NOF_avg', 'NOF_max', 'NOF_sum',\n",
    "                  'NOM_avg', 'NOM_max', 'NOM_sum',\n",
    "                  'NSF_avg', 'NSF_max', 'NSF_sum',\n",
    "                  'NSM_avg', 'NSM_max', 'NSM_sum',\n",
    "                  'ACD_avg', 'ACD_max', 'ACD_sum',\n",
    "                  'NOI_avg', 'NOI_max', 'NOI_sum',\n",
    "                  'NOT_avg', 'NOT_max', 'NOT_sum',\n",
    "                  'TLOC_avg', 'TLOC_max', 'TLOC_sum',\n",
    "                  'NOCU', 'pre']\n",
    "\n",
    "# Split predictor variables from class labels (training set)\n",
    "x_train = train_data[pred_variables]\n",
    "y_train = [0 if x == 0 else 1 for x in train_data['post']]\n",
    "\n",
    "# Split predictor variables from class labels (test set)\n",
    "x_test = test_data[pred_variables]\n",
    "y_test = [0 if x == 0 else 1 for x in test_data['post']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     FOUT_avg  FOUT_max  FOUT_sum   MLOC_avg  MLOC_max  MLOC_sum   NBD_avg  \\\n",
      "0    5.980769      29.0     311.0   9.230769      55.0     480.0  1.826923   \n",
      "1    4.000000      22.0     168.0   6.666667      32.0     280.0  1.357143   \n",
      "2    4.321267      33.0     955.0   7.027149      83.0    1553.0  1.452489   \n",
      "3    3.752941      80.0     319.0   6.517647     118.0     554.0  1.564706   \n",
      "4    6.552632      63.0     996.0  10.736842      75.0    1632.0  2.052632   \n",
      "..        ...       ...       ...        ...       ...       ...       ...   \n",
      "372  1.750000      11.0      28.0   3.437500      16.0      55.0  1.250000   \n",
      "373  2.764706      19.0      47.0   5.705882      29.0      97.0  1.352941   \n",
      "374  2.000000      10.0      32.0   3.500000      16.0      56.0  1.375000   \n",
      "375  6.700000      61.0     201.0  12.200000      92.0     366.0  1.733333   \n",
      "376  3.759259      16.0     203.0   8.333333      30.0     450.0  1.888889   \n",
      "\n",
      "     NBD_max  NBD_sum   PAR_avg  ...  NOI_max  NOI_sum   NOT_avg  NOT_max  \\\n",
      "0        6.0     95.0  1.173077  ...      0.0      0.0  1.000000      1.0   \n",
      "1        6.0     57.0  1.095238  ...      1.0      1.0  0.666667      1.0   \n",
      "2        5.0    321.0  0.800905  ...      1.0      2.0  0.904762      1.0   \n",
      "3        6.0    133.0  1.517647  ...      0.0      0.0  1.000000      1.0   \n",
      "4        8.0    312.0  0.796053  ...      0.0      0.0  1.000000      1.0   \n",
      "..       ...      ...       ...  ...      ...      ...       ...      ...   \n",
      "372      3.0     20.0  0.437500  ...      0.0      0.0  1.000000      1.0   \n",
      "373      3.0     23.0  0.470588  ...      0.0      0.0  1.000000      1.0   \n",
      "374      3.0     22.0  0.500000  ...      0.0      0.0  1.000000      1.0   \n",
      "375      4.0     52.0  0.666667  ...      0.0      0.0  1.000000      1.0   \n",
      "376      4.0    102.0  1.740741  ...      0.0      0.0  1.000000      1.0   \n",
      "\n",
      "     NOT_sum    TLOC_avg  TLOC_max  TLOC_sum  NOCU  pre  \n",
      "0        7.0  112.000000     277.0     784.0   7.0    5  \n",
      "1        2.0  140.000000     386.0     420.0   3.0    2  \n",
      "2       19.0  116.000000     679.0    2436.0  21.0    9  \n",
      "3        9.0   99.444444     219.0     895.0   9.0    2  \n",
      "4        9.0  253.444444     724.0    2281.0   9.0    6  \n",
      "..       ...         ...       ...       ...   ...  ...  \n",
      "372      2.0   54.000000      77.0     108.0   2.0    0  \n",
      "373      2.0   78.500000     127.0     157.0   2.0    0  \n",
      "374      2.0   53.500000      77.0     107.0   2.0    0  \n",
      "375      5.0  105.200000     176.0     526.0   5.0    3  \n",
      "376      8.0   83.875000     259.0     671.0   8.0    1  \n",
      "\n",
      "[377 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "# All 41 features for each data instance (377 in total)\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "# All 377 class labels\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclipse_tr = tree_grow(x_train, y_train, nmin=15, minleaf=5, nfeat=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

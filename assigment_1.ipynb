{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "from statistics import mode\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, value=None, left=None, right=None):\n",
    "        self.feature = feature # feature index\n",
    "        self.threshold = threshold # feature threshold\n",
    "        self.value = value # feature index majority\n",
    "        self.left = left # child nodes\n",
    "        self.right = right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_grow(x, y, nmin, minleaf, nfeat):\n",
    "    \"\"\"\n",
    "    Grow a decision tree based on the input data\n",
    "\n",
    "    Args:\n",
    "        x (list of lists): List of data points\n",
    "        y (list): List of labels corresponding to data points\n",
    "        nmin (int): Minimum number of data points required for a node\n",
    "        minleaf (int): Minimum number of data points required for a leaf node\n",
    "        nfeat (int): Number of random features to consider for splitting\n",
    "\n",
    "    Returns:\n",
    "        Node: Root node of the decision tree\n",
    "    \"\"\"\n",
    "\n",
    "    if pure(y): # if pure return majority class\n",
    "        return Node(value=mode(y))\n",
    "\n",
    "    if len(y) < nmin: # if fewer cases than nmin majority class\n",
    "        return Node(value=mode(y))\n",
    "\n",
    "    feature, threshold, leftx, rightx, lefty, righty = split(x, y, minleaf, nfeat) # GINI search\n",
    "    if feature == None: # no split so node becomes leaf\n",
    "        return Node(value=mode(y))\n",
    "\n",
    "    left_child = tree_grow(leftx, lefty, nmin, minleaf, nfeat)\n",
    "    right_child = tree_grow(rightx, righty, nmin, minleaf, nfeat)\n",
    "\n",
    "    parent = Node()\n",
    "    parent.feature = feature\n",
    "    parent.threshold = threshold \n",
    "    parent.left = left_child\n",
    "    parent.right = right_child\n",
    "    parent.value = mode(y)\n",
    "    return parent\n",
    "\n",
    "        \n",
    "def tree_pred(x, tr):\n",
    "    \"\"\"\n",
    "    Make predictions using a decision tree\n",
    "\n",
    "    Args:\n",
    "        x (list of lists): List of data points to make predictions on\n",
    "        tr (Node): Root node of the decision tree\n",
    "\n",
    "    Returns:\n",
    "        list: Predicted labels for the input data points\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        current_node = tr\n",
    "        while current_node.value == None:\n",
    "            if x[i][current_node.feature] <= current_node.threshold:\n",
    "                current_node = current_node.left\n",
    "            else:\n",
    "                current_node = current_node.right\n",
    "        predictions.append(current_node.value)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "def tree_grow_b(x, y, nmin, minleaf, nfeat, m):\n",
    "    \"\"\"\n",
    "    Grow multiple decision trees using bootstrapped samples\n",
    "\n",
    "    Args:\n",
    "        x (list of lists): List of data points\n",
    "        y (list): List of labels corresponding to data points\n",
    "        nmin (int): Minimum number of data points required for a node\n",
    "        minleaf (int): Minimum number of data points required for a leaf node\n",
    "        nfeat (int): Number of random features to consider for splitting\n",
    "        m (int): Number of trees to grow\n",
    "\n",
    "    Returns:\n",
    "        list: List of root nodes of the grown decision trees\n",
    "    \"\"\"\n",
    "    trees = []\n",
    "\n",
    "    for _ in range(m):\n",
    "        bootstrap_i = np.random.choice(len(x), len(x), replace=True)\n",
    "        x_b = [x[i] for i in bootstrap_i]\n",
    "        y_b = [y[i] for i in bootstrap_i]\n",
    "        trees.append(tree_grow(x_b, y_b, nmin, minleaf, nfeat))\n",
    "\n",
    "    return trees\n",
    "\n",
    "\n",
    "def tree_pred_b(trees, x):\n",
    "    \"\"\"\n",
    "    Make predictions using multiple decision trees\n",
    "\n",
    "    Args:\n",
    "        trees (list): List of root nodes of decision trees\n",
    "        x (list of lists): List of data points to make predictions on\n",
    "\n",
    "    Returns:\n",
    "        list: Predicted labels for the input data points\n",
    "    \"\"\"\n",
    "    outcomes = []\n",
    "    new_y = []\n",
    "    for tree in trees:\n",
    "        outcomes.append(tree_pred(x, tree))\n",
    "\n",
    "    for i in range(len(outcomes[0])):\n",
    "        new_y.append([a[i] for a in outcomes])\n",
    "        \n",
    "    new_y = [mode(a) for a in new_y]\n",
    "    return new_y\n",
    "\n",
    "def pure(y):\n",
    "    \"\"\"\n",
    "    Check if all elements in the input list are the same\n",
    "\n",
    "    Args:\n",
    "        y (list): List of elements to check.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if all elements are the same, otherwise False.\n",
    "    \"\"\"\n",
    "    if len(set(y)) == 1: # if all the same classes in remaining \n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def gini(y):\n",
    "    \"\"\"\n",
    "    Calculate the Gini impurity for a given list of labels\n",
    "\n",
    "    Args:\n",
    "        y (list): List of labels.\n",
    "\n",
    "    Returns:\n",
    "        float: Gini impurity value.\n",
    "    \"\"\"\n",
    "    counts = list(Counter(y).values())\n",
    "    p = 0\n",
    "    for count in counts:\n",
    "        p += (count / len(y))**2\n",
    "    return 1 - p\n",
    "\n",
    "def split(x, y, minleaf, nfeat):\n",
    "    \"\"\"\n",
    "    Find the best feature and threshold for splitting data points\n",
    "\n",
    "    Args:\n",
    "        x (list of lists): List of data points.\n",
    "        y (list): List of labels corresponding to data points.\n",
    "        minleaf (int): Minimum number of data points required for a leaf node.\n",
    "        nfeat (int): Number of random features to consider for splitting.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Best feature index, best threshold value,\n",
    "               left child data points, right child data points,\n",
    "               left child labels, right child labels.\n",
    "    \"\"\"\n",
    "    features = random.sample(range(len(x[0])), nfeat) # random features selecting\n",
    "    \n",
    "    best_gini = 1\n",
    "    best_feature = None\n",
    "    best_threshold = None\n",
    "    best_left_indices = []\n",
    "    best_right_indices = []\n",
    "\n",
    "    for feature_index in features:\n",
    "        values = [a[feature_index] for a in x]\n",
    "        for t in range(len(values)):\n",
    "            left_indices = []\n",
    "            right_indices = []\n",
    "            right_values = []\n",
    "            for i, a in enumerate(x): # indices lower than threshold\n",
    "                if a[feature_index] <= values[t]:\n",
    "                    left_indices.append(i)\n",
    "                else:\n",
    "                    right_indices.append(i)\n",
    "                    right_values.append(a[feature_index])\n",
    "\n",
    "            if len(left_indices) >= minleaf and len(right_indices) >= minleaf: # minleaf criteria\n",
    "                left_gini = gini([y[i] for i in left_indices])\n",
    "                right_gini = gini([y[i] for i in right_indices])\n",
    "\n",
    "                weighted_gini = (len(left_indices) / len(y)) * left_gini + (len(right_indices) / len(y)) * right_gini # weighted based on size\n",
    "\n",
    "                if weighted_gini < best_gini:\n",
    "                    if weighted_gini == best_gini and random() == 0: ## if gini same and random == 0, skip if random == 1 replace\n",
    "                        continue\n",
    "                    best_gini = weighted_gini\n",
    "                    best_feature = feature_index\n",
    "                    right_values.sort()\n",
    "                    best_threshold = (values[t] + right_values[0]) / 2\n",
    "                    best_left_indices = left_indices\n",
    "                    best_right_indices = right_indices\n",
    "\n",
    "    # from indices to rows\n",
    "    best_left_x = [a for i, a in enumerate(x) if i in best_left_indices]\n",
    "    best_right_x = [a for i, a in enumerate(x) if i in best_right_indices]\n",
    "    best_left_y = [a for i, a in enumerate(y) if i in best_left_indices]\n",
    "    best_right_y = [a for i, a in enumerate(y) if i in best_right_indices]\n",
    "\n",
    "    return best_feature, best_threshold, best_left_x, best_right_x, best_left_y, best_right_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "file_path = 'data/credit.txt'\n",
    "df = pd.read_csv(file_path, delimiter=',')\n",
    "x = df.drop(columns='class').values.tolist()\n",
    "y = df['class'].values.tolist()\n",
    "\n",
    "tree = tree_grow_b(x,y, 2, 1, 5, 4)\n",
    "print(tree_pred_b(tree, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree prediction on x:\n",
      "prediction [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
      "actual y [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
      "\n",
      "\n",
      "----- node 1 ------\n",
      "feature 3\n",
      "threshold 36.0\n",
      "----- node 1 - > 2 left -----\n",
      "feature 0\n",
      "threshold 37.0\n",
      "value None\n",
      "----- node 1 -> 2 right -----\n",
      "feature None\n",
      "threshold None\n",
      "value 1\n",
      "----- node 2 -> 3 left -----\n",
      "feature None\n",
      "threshold None\n",
      "value 0\n",
      "----- node 2 -> 3 right -----\n",
      "feature 1\n",
      "threshold 0.5\n",
      "value None\n"
     ]
    }
   ],
   "source": [
    "file_path = 'data/credit.txt'\n",
    "df = pd.read_csv(file_path, delimiter=',')\n",
    "x = df.drop(columns='class').values.tolist()\n",
    "y = df['class'].values.tolist()\n",
    "\n",
    "tree = tree_grow(x,y, 2, 1, 5)\n",
    "\n",
    "print('tree prediction on x:')\n",
    "print('prediction', tree_pred(x,tree))\n",
    "print('actual y', y)\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('----- node 1 ------')\n",
    "print('feature', tree.feature)\n",
    "print('threshold', tree.threshold)\n",
    "print('----- node 1 - > 2 left -----')\n",
    "print('feature', tree.left.feature)\n",
    "print('threshold', tree.left.threshold)\n",
    "print('value', tree.left.value)\n",
    "print('----- node 1 -> 2 right -----')\n",
    "print('feature', tree.right.feature)\n",
    "print('threshold', tree.right.threshold)\n",
    "print('value', tree.right.value)\n",
    "print('----- node 2 -> 3 left -----')\n",
    "print('feature', tree.left.left.feature)\n",
    "print('threshold', tree.left.left.threshold)\n",
    "print('value', tree.left.left.value)\n",
    "print('----- node 2 -> 3 right -----')\n",
    "print('feature', tree.left.right.feature)\n",
    "print('threshold', tree.left.right.threshold)\n",
    "print('value', tree.left.right.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boom net niet zelfde als in slides, daar eerste split op feature 3 maar op 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[441  59]\n",
      " [ 51 217]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/pima.txt', header=None)\n",
    "x = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "tree = tree_grow(x,y, 20, 5, 8)\n",
    "\n",
    "cm = metrics.confusion_matrix(y, tree_pred(x, tree))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1: Single Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 2.0 Ecplise data as training set \n",
    "train_data = pd.read_csv('data/eclipse-metrics-packages-2.0.csv', delimiter=';')\n",
    "\n",
    "# Load 3.0 Ecplise data as test set\n",
    "test_data = pd.read_csv('data/eclipse-metrics-packages-3.0.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All 41 predictor variables \n",
    "pred_variables = ['FOUT_avg', 'FOUT_max', 'FOUT_sum',\n",
    "                  'MLOC_avg', 'MLOC_max', 'MLOC_sum',\n",
    "                  'NBD_avg', 'NBD_max', 'NBD_sum',\n",
    "                  'PAR_avg', 'PAR_max', 'PAR_sum',\n",
    "                  'VG_avg', 'VG_max', 'VG_sum',\n",
    "                  'NOF_avg', 'NOF_max', 'NOF_sum',\n",
    "                  'NOM_avg', 'NOM_max', 'NOM_sum',\n",
    "                  'NSF_avg', 'NSF_max', 'NSF_sum',\n",
    "                  'NSM_avg', 'NSM_max', 'NSM_sum',\n",
    "                  'ACD_avg', 'ACD_max', 'ACD_sum',\n",
    "                  'NOI_avg', 'NOI_max', 'NOI_sum',\n",
    "                  'NOT_avg', 'NOT_max', 'NOT_sum',\n",
    "                  'TLOC_avg', 'TLOC_max', 'TLOC_sum',\n",
    "                  'NOCU', 'pre']\n",
    "\n",
    "# Split predictor variables from class labels (training set)\n",
    "x_train = train_data[pred_variables].values\n",
    "y_train = [0 if x == 0 else 1 for x in train_data['post']]\n",
    "\n",
    "# Split predictor variables from class labels (test set)\n",
    "x_test = test_data[pred_variables].values\n",
    "y_test = [0 if x == 0 else 1 for x in test_data['post']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclipse_tree = tree_grow(x_train, y_train, nmin=15, minleaf=5, nfeat=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root - Feature: 40, Threshold: 4.5, Value: 1\n",
      "  Left Child - Feature: 13, Threshold: 26.5, Value: 0\n",
      "    Left Child - Feature: 26, Threshold: 54.5, Value: 0\n",
      "    Right Child - Feature: 14, Threshold: 358.0, Value: 1\n",
      "  Right Child - Feature: 30, Threshold: 0.1583333333333333, Value: 1\n",
      "    Left Child - Feature: 40, Threshold: 11.5, Value: 1\n",
      "    Right Child - Feature: 39, Threshold: 9.5, Value: 1\n"
     ]
    }
   ],
   "source": [
    "def visualize_tree(node, depth=0, parent_side=None, st=False):\n",
    "    if node is not None:\n",
    "        # Print the node's information with indentation based on its depth in the tree\n",
    "        indent = \"  \" * depth\n",
    "        if parent_side is not None:\n",
    "            side_label = \"Left Child\" if parent_side == \"left\" else \"Right Child\"\n",
    "            print(f\"{indent}{side_label} - Feature: {node.feature}, Threshold: {node.threshold}, Value: {node.value}\")\n",
    "        else:\n",
    "            print(f\"{indent}Root - Feature: {node.feature}, Threshold: {node.threshold}, Value: {node.value}\")\n",
    "        \n",
    "        # Recursively visualize the left and right subtrees\n",
    "        st += 1\n",
    "        if st < 3:\n",
    "            visualize_tree(node.left, depth + 1, parent_side=\"left\", st=st)\n",
    "            visualize_tree(node.right, depth + 1, parent_side=\"right\", st=st)\n",
    "\n",
    "visualize_tree(eclipse_tree, st=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre\n",
      "VG_max\n",
      "NOI_avg\n"
     ]
    }
   ],
   "source": [
    "print(pred_variables[40])\n",
    "print(pred_variables[13])\n",
    "print(pred_variables[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hm/zsyn8st924qb5nbh_1xqt_pc0000gn/T/ipykernel_52142/4292574788.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meclipse_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Print the confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Confusion Matrix:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_train, tree_pred(x_train, eclipse_tree))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6822995461422088\n",
      "Precision:  0.6928838951310862\n",
      "Recall:  0.5910543130990416\n"
     ]
    }
   ],
   "source": [
    "# Predict on test set\n",
    "y_pred = tree_pred(x_test, eclipse_tree)\n",
    "y_true = y_test\n",
    "\n",
    "# Performance metrics\n",
    "print('Accuracy: ', metrics.accuracy_score(y_true, y_pred))\n",
    "print('Precision: ', metrics.precision_score(y_true, y_pred))\n",
    "print('Recall: ', metrics.recall_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2: Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Itereren over features ipv range(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagged_trees = tree_grow_b(x_train, y_train, nmin=15, minleaf=5, nfeat=41, m=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7745839636913767\n",
      "Precision:  0.8178294573643411\n",
      "Recall:  0.6741214057507987\n"
     ]
    }
   ],
   "source": [
    "# Predict on test set\n",
    "y_pred = tree_pred_b(bagged_trees, x_test)\n",
    "y_true = y_test\n",
    "\n",
    "# Performance metrics\n",
    "print('Accuracy: ', metrics.accuracy_score(y_true, y_pred))\n",
    "print('Precision: ', metrics.precision_score(y_true, y_pred))\n",
    "print('Recall: ', metrics.recall_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Itereren over range(len(features)) (wat we oorspronkelijk hadden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagged_trees = tree_grow_b(x_train, y_train, nmin=15, minleaf=5, nfeat=41, m=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.773071104387292\n",
      "Precision:  0.8221343873517787\n",
      "Recall:  0.6645367412140575\n"
     ]
    }
   ],
   "source": [
    "# Predict on test set\n",
    "y_pred = tree_pred_b(bagged_trees, x_test)\n",
    "y_true = y_test\n",
    "\n",
    "# Performance metrics\n",
    "print('Accuracy: ', metrics.accuracy_score(y_true, y_pred))\n",
    "print('Precision: ', metrics.precision_score(y_true, y_pred))\n",
    "print('Recall: ', metrics.recall_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Itereren over features ipv range(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = tree_grow_b(x_train, y_train, nmin=15, minleaf=5, nfeat=6, m=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7594553706505295\n",
      "Precision:  0.7769784172661871\n",
      "Recall:  0.6900958466453674\n"
     ]
    }
   ],
   "source": [
    "# Predict on test set\n",
    "y_pred = tree_pred_b(random_forest, x_test)\n",
    "y_true = y_test\n",
    "\n",
    "# Performance metrics\n",
    "print('Accuracy: ', metrics.accuracy_score(y_true, y_pred))\n",
    "print('Precision: ', metrics.precision_score(y_true, y_pred))\n",
    "print('Recall: ', metrics.recall_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Itereren over range(len(features)) (wat we oorspronkelijk hadden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = tree_grow_b(x_train, y_train, nmin=15, minleaf=5, nfeat=6, m=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.649016641452345\n",
      "Precision:  0.6167146974063401\n",
      "Recall:  0.6837060702875399\n"
     ]
    }
   ],
   "source": [
    "# Predict on test set\n",
    "y_pred = tree_pred_b(random_forest, x_test)\n",
    "y_true = y_test\n",
    "\n",
    "# Performance metrics\n",
    "print('Accuracy: ', metrics.accuracy_score(y_true, y_pred))\n",
    "print('Precision: ', metrics.precision_score(y_true, y_pred))\n",
    "print('Recall: ', metrics.recall_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
